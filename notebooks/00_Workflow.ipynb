{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb80692-1b47-4ce9-b93a-586b8d8ecdd7",
   "metadata": {},
   "source": [
    "# Workflow and Data Pipeline\n",
    "* object tracking with YOLO and DeepSORT\n",
    "* trajectory analysis for specific object\n",
    "* plot trajectory, velocity and acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b62af3-3c33-4eb6-8931-7b6cf69e61bb",
   "metadata": {},
   "source": [
    "## Record and Upload Video\n",
    "Record a Video and upload it to `./data/raw/<session-name>`\n",
    "\n",
    "*t.b.d.: hints for video recording*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07533b56-87d2-4b07-82a3-52d630807a4d",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Video is processed by \"Yolov5 + StrongSORT with OSNet\"(https://github.com/mikel-brostrom/Yolov5_StrongSORT_OSNet). \n",
    "\n",
    "*t.b.d.: describe model and parameter!*\n",
    "\n",
    "*How to use the \"Yolov5 + StrongSORT with OSNet\" in this scope?*\n",
    "\n",
    "Results are stored in `./data/interim/<session-name>`:\n",
    "* video with detections bounding boxes\n",
    "* txt-file in MOT-Challange format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf711d3c-e181-49bc-bcd4-7344fe82a3d1",
   "metadata": {},
   "source": [
    "### MOT-Challeng Data Format\n",
    "https://motchallenge.net/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0899a7-f3b5-4fb6-a532-3c43afbfbbb2",
   "metadata": {},
   "source": [
    "| Position | Name | Description |\n",
    "| -------- | -----| ------------|\n",
    "| 0 | Frame number | Indicate at which frame the object is present |\n",
    "| 1 | Identity number | Each pedestrian trajectory is identified by a unique ID (âˆ’1 for detections) |\n",
    "| 2 | Bounding box *x* | left Coordinate of the top-left corner of the pedestrian bounding box |\n",
    "| 3 | Bounding box *y* | top Coordinate of the top-left corner of the pedestrian bounding box |\n",
    "| 4 | Bounding box *w* | width Width in pixels of the pedestrian bounding box |\n",
    "| 5 | Bounding box *h* | height Height in pixels of the pedestrian bounding box |\n",
    "| 6 (DET) | Confidence score | DET: Indicates how confident the detector is that this instance is a pedestrian. |\n",
    "| 6 (GT)  | Class Visibility | It acts as a flag whether the entry is to be considered (1) or ignored (0). |\n",
    "| 7 (GT)  | Class Visibility | Indicates the type of object annotated |\n",
    "| 8 (GF)  | Class Visibility | Visibility ratio, a number between 0 and 1 that says how much of that object is visible. Can be due to occlusion and due to image border cropping. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c224a-b0fb-4384-ae8b-fff8eaaecf2b",
   "metadata": {},
   "source": [
    "## Generating Test and Trainings Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e902b8a3-f54c-4b49-b897-d16039dfde5b",
   "metadata": {},
   "source": [
    "### Artificial Data\n",
    "* .txt-file only\n",
    "* generating data with Mujoco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de56302-6438-4989-b714-59296cc00d08",
   "metadata": {},
   "source": [
    "### Real Video Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b18da9d-653a-48d7-9026-1966b8c5397a",
   "metadata": {},
   "source": [
    "## Physics Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c92d980-aee0-4134-a0a0-b37f5ee478b0",
   "metadata": {},
   "source": [
    "### Method 1\n",
    "\n",
    "* Devide image in areas\n",
    "* Calculate velocity based on leaving / entering areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9475a0-5e3d-4cb6-a830-7defb50a2ff4",
   "metadata": {},
   "source": [
    "### Method 1b\n",
    "\n",
    "* Devide image in areas\n",
    "* Calculate velocity based on leaving / entering areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a5d14-b3c2-407d-868b-6b9149aaaf4b",
   "metadata": {},
   "source": [
    "### Method 2\n",
    "Using only the .txt-file with the object-id and bounding-box-information per frame. \n",
    "\n",
    "Assumtions: Complete physics information can be expressed with Kalman-State-Transition matrix $F$.\n",
    "\n",
    "* Use NN to find optimal Kalman-Filter-Parameters $F_{i,j}$\n",
    "* Plot trajectory using $F$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce155e1-7e10-4b1b-b05c-6c3a91409bc1",
   "metadata": {},
   "source": [
    "### Method 3\n",
    "Using .txt-file and image-information to increase prediction quatily:\n",
    "* Add physical data (mass) by assumtions about detected objects\n",
    "  * sports ball weight ~ 300g\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9952b7e-2a69-4ba1-9e7c-0aece36fc330",
   "metadata": {},
   "source": [
    "### Method 3\n",
    "Use Mujoco - Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412bff89-26f5-4350-a7ce-7ff84ace41d2",
   "metadata": {},
   "source": [
    "## Improve Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986dae38-0351-4807-8cfa-38c0f149b20a",
   "metadata": {},
   "source": [
    "* Improve Quality of recorded videos\n",
    "* Adjust tracking-algorithm parameters for better detections:\n",
    "  * change YOLO and StrongSORT model\n",
    "  * retrain YOLO model\n",
    "  * change weight $\\lambda$ (appearance vs Kalman cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd34ed-c7d3-45bc-a90e-58a6dbc74977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physicai",
   "language": "python",
   "name": "physicai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
